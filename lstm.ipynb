{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ozge.bursa/opt/anaconda3/lib/python3.7/site-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
      "  import pandas.util.testing as tm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from pylab import rcParams\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rc\n",
    "from pandas.plotting import register_matplotlib_converters\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format='retina'\n",
    "\n",
    "register_matplotlib_converters()\n",
    "sns.set(style='whitegrid', palette='muted', font_scale=1.5)\n",
    "\n",
    "rcParams['figure.figsize'] = 22, 10\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "\n",
    "np.random.seed(RANDOM_SEED)\n",
    "tf.random.set_random_seed(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = ['user_id', 'activity', 'timestamp', 'x_axis', 'y_axis', 'z_axis']\n",
    "\n",
    "df = pd.read_csv('../data/WISDM_ar_v1.1_raw.txt', header=None, names=column_names)\n",
    "df.z_axis.replace(regex=True, inplace=True, to_replace=r';', value=r'')\n",
    "df['z_axis'] = df.z_axis.astype(np.float64)\n",
    "df.dropna(axis=0, how='any', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>activity</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>x_axis</th>\n",
       "      <th>y_axis</th>\n",
       "      <th>z_axis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>33</td>\n",
       "      <td>Jogging</td>\n",
       "      <td>49105962326000</td>\n",
       "      <td>-0.694638</td>\n",
       "      <td>12.680544</td>\n",
       "      <td>0.503953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>33</td>\n",
       "      <td>Jogging</td>\n",
       "      <td>49106062271000</td>\n",
       "      <td>5.012288</td>\n",
       "      <td>11.264028</td>\n",
       "      <td>0.953424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>33</td>\n",
       "      <td>Jogging</td>\n",
       "      <td>49106112167000</td>\n",
       "      <td>4.903325</td>\n",
       "      <td>10.882658</td>\n",
       "      <td>-0.081722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33</td>\n",
       "      <td>Jogging</td>\n",
       "      <td>49106222305000</td>\n",
       "      <td>-0.612916</td>\n",
       "      <td>18.496431</td>\n",
       "      <td>3.023717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>33</td>\n",
       "      <td>Jogging</td>\n",
       "      <td>49106332290000</td>\n",
       "      <td>-1.184970</td>\n",
       "      <td>12.108489</td>\n",
       "      <td>7.205164</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id activity       timestamp    x_axis     y_axis    z_axis\n",
       "0       33  Jogging  49105962326000 -0.694638  12.680544  0.503953\n",
       "1       33  Jogging  49106062271000  5.012288  11.264028  0.953424\n",
       "2       33  Jogging  49106112167000  4.903325  10.882658 -0.081722\n",
       "3       33  Jogging  49106222305000 -0.612916  18.496431  3.023717\n",
       "4       33  Jogging  49106332290000 -1.184970  12.108489  7.205164"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([33, 17, 20, 29, 13, 15,  6, 27, 36, 18, 32, 35, 11, 16,  5, 10, 28,\n",
       "       26, 14, 24, 12, 23,  4, 30, 34,  8, 31, 21,  3, 22,  1,  9, 25,  2,\n",
       "        7, 19])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.user_id.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df[df['user_id'] <= 30]\n",
    "df_test = df[df['user_id'] > 30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ozge.bursa/opt/anaconda3/lib/python3.7/site-packages/pandas/core/indexing.py:966: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[item] = s\n",
      "/Users/ozge.bursa/opt/anaconda3/lib/python3.7/site-packages/pandas/core/indexing.py:966: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[item] = s\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "scale_columns = ['x_axis', 'y_axis', 'z_axis']\n",
    "\n",
    "scaler = RobustScaler()\n",
    "\n",
    "scaler = scaler.fit(df_train[scale_columns])\n",
    "\n",
    "df_train.loc[:, scale_columns] = scaler.transform(df_train[scale_columns].to_numpy())\n",
    "df_test.loc[:, scale_columns] = scaler.transform(df_test[scale_columns].to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "\n",
    "def create_dataset(X, y, time_steps=1, step=1):\n",
    "    Xs, ys = [], []\n",
    "    for i in range(0, len(X) - time_steps, step):\n",
    "        v = X.iloc[i:(i + time_steps)].values\n",
    "        labels = y.iloc[i: i + time_steps]\n",
    "        Xs.append(v)        \n",
    "        ys.append(stats.mode(labels)[0][0])\n",
    "    return np.array(Xs), np.array(ys).reshape(-1, 1)\n",
    "\n",
    "TIME_STEPS = 200\n",
    "STEP = 40\n",
    "\n",
    "X_train, y_train = create_dataset(\n",
    "    df_train[['x_axis', 'y_axis', 'z_axis']], \n",
    "    df_train.activity, \n",
    "    TIME_STEPS, \n",
    "    STEP\n",
    ")\n",
    "\n",
    "X_test, y_test = create_dataset(\n",
    "    df_test[['x_axis', 'y_axis', 'z_axis']], \n",
    "    df_test.activity, \n",
    "    TIME_STEPS, \n",
    "    STEP\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22454, 200, 3) (22454, 1)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "enc = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "\n",
    "enc = enc.fit(y_train)\n",
    "\n",
    "y_train = enc.transform(y_train)\n",
    "y_test = enc.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22454, 200, 3) (22454, 6)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "momentum = [0, 0.2, 0.4, 0.6, 0.8, 0.9]\n",
    "learn_rate = [0.001, 0.01, 0.1, 0.2, 0.3]   \n",
    "batch_size = [64, 128]\n",
    "epochs = [20, 50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/ozge.bursa/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/ops/init_ops.py:97: calling GlorotUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /Users/ozge.bursa/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/ops/init_ops.py:97: calling Orthogonal.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /Users/ozge.bursa/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/ops/init_ops.py:97: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /Users/ozge.bursa/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "WARNING:tensorflow:From /Users/ozge.bursa/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Train on 20208 samples, validate on 2246 samples\n",
      "Epoch 1/20\n",
      "20208/20208 [==============================] - 104s 5ms/sample - loss: 1.0425 - acc: 0.6443 - val_loss: 0.8944 - val_acc: 0.6451\n",
      "Epoch 2/20\n",
      "20208/20208 [==============================] - 97s 5ms/sample - loss: 0.7197 - acc: 0.7393 - val_loss: 0.5229 - val_acc: 0.8526\n",
      "Epoch 3/20\n",
      "20208/20208 [==============================] - 98s 5ms/sample - loss: 0.6112 - acc: 0.7767 - val_loss: 0.5340 - val_acc: 0.8117\n",
      "Epoch 4/20\n",
      "20208/20208 [==============================] - 100s 5ms/sample - loss: 0.5476 - acc: 0.7996 - val_loss: 0.3467 - val_acc: 0.8878\n",
      "Epoch 5/20\n",
      "20208/20208 [==============================] - 101s 5ms/sample - loss: 0.4925 - acc: 0.8111 - val_loss: 0.4475 - val_acc: 0.8379\n",
      "Epoch 6/20\n",
      "20208/20208 [==============================] - 111s 6ms/sample - loss: 0.4069 - acc: 0.8405 - val_loss: 0.4197 - val_acc: 0.8673\n",
      "Epoch 7/20\n",
      "20208/20208 [==============================] - 111s 5ms/sample - loss: 0.3637 - acc: 0.8659 - val_loss: 0.4797 - val_acc: 0.8272\n",
      "Epoch 8/20\n",
      "20208/20208 [==============================] - 108s 5ms/sample - loss: 0.3765 - acc: 0.8563 - val_loss: 0.3852 - val_acc: 0.8856\n",
      "Epoch 9/20\n",
      "20208/20208 [==============================] - 115s 6ms/sample - loss: 0.3695 - acc: 0.8591 - val_loss: 0.5098 - val_acc: 0.8442\n",
      "Epoch 10/20\n",
      "20208/20208 [==============================] - 108s 5ms/sample - loss: 0.2803 - acc: 0.8972 - val_loss: 0.4223 - val_acc: 0.8375\n",
      "Epoch 11/20\n",
      "20208/20208 [==============================] - 106s 5ms/sample - loss: 0.3104 - acc: 0.8902 - val_loss: 0.3628 - val_acc: 0.8526\n",
      "Epoch 12/20\n",
      "20208/20208 [==============================] - 109s 5ms/sample - loss: 0.2550 - acc: 0.9103 - val_loss: 0.4636 - val_acc: 0.8767\n",
      "Epoch 13/20\n",
      "20208/20208 [==============================] - 103s 5ms/sample - loss: 0.3142 - acc: 0.8814 - val_loss: 0.6616 - val_acc: 0.8339\n",
      "Epoch 14/20\n",
      "12928/20208 [==================>...........] - ETA: 36s - loss: 0.2763 - acc: 0.9007"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(\n",
    "    keras.layers.Bidirectional(\n",
    "      keras.layers.LSTM(\n",
    "          units=128, \n",
    "          input_shape=[X_train.shape[1], X_train.shape[2]]\n",
    "      )\n",
    "    )\n",
    ")\n",
    "model.add(keras.layers.Dropout(rate=0.5))\n",
    "model.add(keras.layers.Dense(units=128, activation='relu'))\n",
    "model.add(keras.layers.Dense(y_train.shape[1], activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['acc'])\n",
    "history = model.fit(X_train, y_train, epochs=20, batch_size=64, validation_split=0.1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = [X_train.shape[1], X_train.shape[2]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "momentum = [0, 0.2, 0.6, 0.9]\n",
    "learn_rate = [0.001, 0.01, 0.1]   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(learn_rate=0.01, momentum=0):\n",
    "    model = keras.Sequential()\n",
    "    model.add(\n",
    "        keras.layers.Bidirectional(\n",
    "          keras.layers.LSTM(\n",
    "              units=128, \n",
    "              input_shape=input_shape\n",
    "          )\n",
    "        )\n",
    "    )\n",
    "    model.add(keras.layers.Dropout(rate=0.5))\n",
    "    model.add(keras.layers.Dense(units=128, activation='relu'))\n",
    "    model.add(keras.layers.Dense(y_train.shape[1], activation='softmax'))\n",
    "    # Compile model\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['acc'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = dict(learn_rate=learn_rate, momentum=momentum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KerasClassifier(build_fn=create_model, epochs=10, batch_size=64)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=1, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 17963 samples\n",
      "Epoch 1/10\n",
      "17963/17963 [==============================] - 89s 5ms/sample - loss: 1.0760 - acc: 0.6323\n",
      "Epoch 2/10\n",
      "17963/17963 [==============================] - 93s 5ms/sample - loss: 0.7476 - acc: 0.7380\n",
      "Epoch 3/10\n",
      "17963/17963 [==============================] - 90s 5ms/sample - loss: 0.5911 - acc: 0.7888\n",
      "Epoch 4/10\n",
      "17963/17963 [==============================] - 91s 5ms/sample - loss: 0.5725 - acc: 0.7961\n",
      "Epoch 5/10\n",
      "17963/17963 [==============================] - 91s 5ms/sample - loss: 0.5417 - acc: 0.8016\n",
      "Epoch 6/10\n",
      "17963/17963 [==============================] - 91s 5ms/sample - loss: 0.4241 - acc: 0.8378\n",
      "Epoch 7/10\n",
      "17963/17963 [==============================] - 93s 5ms/sample - loss: 0.4223 - acc: 0.8424\n",
      "Epoch 8/10\n",
      "17963/17963 [==============================] - 93s 5ms/sample - loss: 0.3290 - acc: 0.8764\n",
      "Epoch 9/10\n",
      "17963/17963 [==============================] - 92s 5ms/sample - loss: 0.2963 - acc: 0.8892\n",
      "Epoch 10/10\n",
      "17963/17963 [==============================] - 92s 5ms/sample - loss: 0.2869 - acc: 0.8945\n",
      "4491/4491 [==============================] - 5s 1ms/sample - loss: 0.4020 - acc: 0.8686\n",
      "17963/17963 [==============================] - 18s 976us/sample - loss: 0.2661 - acc: 0.9027\n",
      "Train on 17963 samples\n",
      "Epoch 1/10\n",
      "17963/17963 [==============================] - 94s 5ms/sample - loss: 1.0227 - acc: 0.6550\n",
      "Epoch 2/10\n",
      "17963/17963 [==============================] - 95s 5ms/sample - loss: 0.7119 - acc: 0.7535\n",
      "Epoch 3/10\n",
      "17963/17963 [==============================] - 95s 5ms/sample - loss: 0.5165 - acc: 0.8168\n",
      "Epoch 4/10\n",
      "17963/17963 [==============================] - 94s 5ms/sample - loss: 0.5024 - acc: 0.8188\n",
      "Epoch 5/10\n",
      "17963/17963 [==============================] - 93s 5ms/sample - loss: 0.4728 - acc: 0.8286\n",
      "Epoch 6/10\n",
      "17963/17963 [==============================] - 98s 5ms/sample - loss: 0.4094 - acc: 0.8515\n",
      "Epoch 7/10\n",
      "17963/17963 [==============================] - 95s 5ms/sample - loss: 0.3418 - acc: 0.8715\n",
      "Epoch 8/10\n",
      "17963/17963 [==============================] - 100s 6ms/sample - loss: 0.3200 - acc: 0.8797\n",
      "Epoch 9/10\n",
      "17963/17963 [==============================] - 96s 5ms/sample - loss: 0.3132 - acc: 0.8862\n",
      "Epoch 10/10\n",
      "17963/17963 [==============================] - 114s 6ms/sample - loss: 0.2656 - acc: 0.9034\n",
      "4491/4491 [==============================] - 5s 1ms/sample - loss: 0.6888 - acc: 0.8087\n",
      "17963/17963 [==============================] - 20s 1ms/sample - loss: 0.2587 - acc: 0.9137\n",
      "Train on 17963 samples\n",
      "Epoch 1/10\n",
      "17963/17963 [==============================] - 112s 6ms/sample - loss: 1.0529 - acc: 0.6453\n",
      "Epoch 2/10\n",
      "17963/17963 [==============================] - 110s 6ms/sample - loss: 0.8450 - acc: 0.7116\n",
      "Epoch 3/10\n",
      "17963/17963 [==============================] - 105s 6ms/sample - loss: 0.7055 - acc: 0.7514\n",
      "Epoch 4/10\n",
      "17963/17963 [==============================] - 98s 5ms/sample - loss: 0.6104 - acc: 0.7769\n",
      "Epoch 5/10\n",
      "17963/17963 [==============================] - 107s 6ms/sample - loss: 0.5639 - acc: 0.7917\n",
      "Epoch 6/10\n",
      "17963/17963 [==============================] - 96s 5ms/sample - loss: 0.5125 - acc: 0.8046\n",
      "Epoch 7/10\n",
      "17963/17963 [==============================] - 89s 5ms/sample - loss: 0.4288 - acc: 0.8325\n",
      "Epoch 8/10\n",
      "17963/17963 [==============================] - 112s 6ms/sample - loss: 0.4258 - acc: 0.8321\n",
      "Epoch 9/10\n",
      "17963/17963 [==============================] - 108s 6ms/sample - loss: 0.6741 - acc: 0.7602\n",
      "Epoch 10/10\n",
      "17963/17963 [==============================] - 117s 6ms/sample - loss: 0.5433 - acc: 0.8051\n",
      "4491/4491 [==============================] - 8s 2ms/sample - loss: 0.9500 - acc: 0.6782\n",
      "17963/17963 [==============================] - 22s 1ms/sample - loss: 0.5808 - acc: 0.7707\n",
      "Train on 17963 samples\n",
      "Epoch 1/10\n",
      "17963/17963 [==============================] - 104s 6ms/sample - loss: 1.0612 - acc: 0.6346\n",
      "Epoch 2/10\n",
      "17963/17963 [==============================] - 89s 5ms/sample - loss: 0.8342 - acc: 0.7172\n",
      "Epoch 3/10\n",
      "17963/17963 [==============================] - 89s 5ms/sample - loss: 0.6484 - acc: 0.7706\n",
      "Epoch 4/10\n",
      "17963/17963 [==============================] - 86s 5ms/sample - loss: 0.4650 - acc: 0.8230\n",
      "Epoch 5/10\n",
      "17963/17963 [==============================] - 90s 5ms/sample - loss: 0.4288 - acc: 0.8385\n",
      "Epoch 6/10\n",
      "17963/17963 [==============================] - 86s 5ms/sample - loss: 0.3395 - acc: 0.8724\n",
      "Epoch 7/10\n",
      "17963/17963 [==============================] - 89s 5ms/sample - loss: 0.5094 - acc: 0.8202\n",
      "Epoch 8/10\n",
      "17963/17963 [==============================] - 85s 5ms/sample - loss: 0.4118 - acc: 0.8442\n",
      "Epoch 9/10\n",
      "17963/17963 [==============================] - 89s 5ms/sample - loss: 0.3188 - acc: 0.8789\n",
      "Epoch 10/10\n",
      "17963/17963 [==============================] - 96s 5ms/sample - loss: 0.2751 - acc: 0.9007\n",
      "4491/4491 [==============================] - 5s 1ms/sample - loss: 0.7962 - acc: 0.7731\n",
      "17963/17963 [==============================] - 20s 1ms/sample - loss: 0.1964 - acc: 0.9299\n",
      "Train on 17964 samples\n",
      "Epoch 1/10\n",
      "17964/17964 [==============================] - 111s 6ms/sample - loss: 1.1506 - acc: 0.6019\n",
      "Epoch 2/10\n",
      "17964/17964 [==============================] - 103s 6ms/sample - loss: 1.0076 - acc: 0.6578\n",
      "Epoch 3/10\n",
      "17964/17964 [==============================] - 107s 6ms/sample - loss: 0.8191 - acc: 0.7153\n",
      "Epoch 4/10\n",
      "17964/17964 [==============================] - 99s 6ms/sample - loss: 0.6306 - acc: 0.7688\n",
      "Epoch 5/10\n",
      "17964/17964 [==============================] - 91s 5ms/sample - loss: 0.5412 - acc: 0.8068\n",
      "Epoch 6/10\n",
      "17964/17964 [==============================] - 104s 6ms/sample - loss: 0.6288 - acc: 0.7792\n",
      "Epoch 7/10\n",
      "17964/17964 [==============================] - 94s 5ms/sample - loss: 0.7242 - acc: 0.7396\n",
      "Epoch 8/10\n",
      "17964/17964 [==============================] - 90s 5ms/sample - loss: 0.5065 - acc: 0.8127\n",
      "Epoch 9/10\n",
      "17964/17964 [==============================] - 86s 5ms/sample - loss: 0.4882 - acc: 0.8227\n",
      "Epoch 10/10\n",
      "17964/17964 [==============================] - 86s 5ms/sample - loss: 0.3986 - acc: 0.8552\n",
      "4490/4490 [==============================] - 4s 977us/sample - loss: 0.9021 - acc: 0.6929\n",
      "17964/17964 [==============================] - 16s 902us/sample - loss: 0.3113 - acc: 0.8837\n",
      "Train on 17963 samples\n",
      "Epoch 1/10\n",
      "17963/17963 [==============================] - 86s 5ms/sample - loss: 1.1422 - acc: 0.6149\n",
      "Epoch 2/10\n",
      "17963/17963 [==============================] - 86s 5ms/sample - loss: 0.8426 - acc: 0.7111\n",
      "Epoch 3/10\n",
      "17963/17963 [==============================] - 86s 5ms/sample - loss: 0.6364 - acc: 0.7764\n",
      "Epoch 4/10\n",
      "17963/17963 [==============================] - 86s 5ms/sample - loss: 0.5139 - acc: 0.8147\n",
      "Epoch 5/10\n",
      "17963/17963 [==============================] - 94s 5ms/sample - loss: 0.5310 - acc: 0.8083\n",
      "Epoch 6/10\n",
      "17963/17963 [==============================] - 95s 5ms/sample - loss: 0.7615 - acc: 0.7369\n",
      "Epoch 7/10\n",
      "17963/17963 [==============================] - 102s 6ms/sample - loss: 0.7957 - acc: 0.7405\n",
      "Epoch 8/10\n",
      "17963/17963 [==============================] - 104s 6ms/sample - loss: 0.6389 - acc: 0.7843\n",
      "Epoch 9/10\n",
      "17963/17963 [==============================] - 105s 6ms/sample - loss: 0.7663 - acc: 0.7338\n",
      "Epoch 10/10\n",
      "17963/17963 [==============================] - 104s 6ms/sample - loss: 0.7902 - acc: 0.7286\n",
      "4491/4491 [==============================] - 5s 1ms/sample - loss: 0.7751 - acc: 0.7099\n",
      "17963/17963 [==============================] - 20s 1ms/sample - loss: 0.8289 - acc: 0.7238\n",
      "Train on 17963 samples\n",
      "Epoch 1/10\n",
      "17963/17963 [==============================] - 101s 6ms/sample - loss: 1.0413 - acc: 0.6420\n",
      "Epoch 2/10\n",
      "17963/17963 [==============================] - 101s 6ms/sample - loss: 0.7668 - acc: 0.7321\n",
      "Epoch 3/10\n",
      "17963/17963 [==============================] - 101s 6ms/sample - loss: 0.5649 - acc: 0.7974\n",
      "Epoch 4/10\n",
      "17963/17963 [==============================] - 116s 6ms/sample - loss: 0.4568 - acc: 0.8276\n",
      "Epoch 5/10\n",
      "17963/17963 [==============================] - 110s 6ms/sample - loss: 0.3918 - acc: 0.8507\n",
      "Epoch 6/10\n",
      "17963/17963 [==============================] - 97s 5ms/sample - loss: 0.3265 - acc: 0.8781\n",
      "Epoch 7/10\n",
      "17963/17963 [==============================] - 95s 5ms/sample - loss: 0.4748 - acc: 0.8246\n",
      "Epoch 8/10\n",
      "17963/17963 [==============================] - 98s 5ms/sample - loss: 0.5801 - acc: 0.8003\n",
      "Epoch 9/10\n",
      "17963/17963 [==============================] - 98s 5ms/sample - loss: 0.6694 - acc: 0.7588\n",
      "Epoch 10/10\n",
      "17963/17963 [==============================] - 97s 5ms/sample - loss: 0.5085 - acc: 0.8092\n",
      "4491/4491 [==============================] - 5s 1ms/sample - loss: 0.7857 - acc: 0.7889\n",
      "17963/17963 [==============================] - 18s 1ms/sample - loss: 0.3433 - acc: 0.8626\n",
      "Train on 17963 samples\n",
      "Epoch 1/10\n",
      "17963/17963 [==============================] - 100s 6ms/sample - loss: 1.0814 - acc: 0.6332\n",
      "Epoch 2/10\n",
      "17963/17963 [==============================] - 95s 5ms/sample - loss: 0.8139 - acc: 0.7252\n",
      "Epoch 3/10\n",
      "17963/17963 [==============================] - 100s 6ms/sample - loss: 0.7200 - acc: 0.7490\n",
      "Epoch 4/10\n",
      "17963/17963 [==============================] - 96s 5ms/sample - loss: 0.6872 - acc: 0.7562\n",
      "Epoch 5/10\n",
      "17963/17963 [==============================] - 98s 5ms/sample - loss: 0.5927 - acc: 0.7836\n",
      "Epoch 6/10\n",
      "17963/17963 [==============================] - 91s 5ms/sample - loss: 0.5620 - acc: 0.7901\n",
      "Epoch 7/10\n",
      "17963/17963 [==============================] - 101s 6ms/sample - loss: 0.7938 - acc: 0.7214\n",
      "Epoch 8/10\n",
      "17963/17963 [==============================] - 96s 5ms/sample - loss: 0.7325 - acc: 0.7414\n",
      "Epoch 9/10\n",
      "17963/17963 [==============================] - 97s 5ms/sample - loss: 0.5798 - acc: 0.7866\n",
      "Epoch 10/10\n",
      "17963/17963 [==============================] - 97s 5ms/sample - loss: 0.4173 - acc: 0.8333\n",
      "4491/4491 [==============================] - 5s 1ms/sample - loss: 0.7699 - acc: 0.7760\n",
      "17963/17963 [==============================] - 20s 1ms/sample - loss: 0.4412 - acc: 0.8436\n",
      "Train on 17963 samples\n",
      "Epoch 1/10\n",
      "17963/17963 [==============================] - 102s 6ms/sample - loss: 0.9897 - acc: 0.6763\n",
      "Epoch 2/10\n",
      "17963/17963 [==============================] - 99s 6ms/sample - loss: 0.7622 - acc: 0.7501\n",
      "Epoch 3/10\n",
      "17963/17963 [==============================] - 90s 5ms/sample - loss: 0.6632 - acc: 0.7700\n",
      "Epoch 4/10\n",
      "17963/17963 [==============================] - 95s 5ms/sample - loss: 0.6316 - acc: 0.7812\n",
      "Epoch 5/10\n",
      "17963/17963 [==============================] - 89s 5ms/sample - loss: 0.5751 - acc: 0.8030\n",
      "Epoch 6/10\n",
      "17963/17963 [==============================] - 88s 5ms/sample - loss: 0.5617 - acc: 0.8040\n",
      "Epoch 7/10\n",
      "17963/17963 [==============================] - 87s 5ms/sample - loss: 0.4834 - acc: 0.8272\n",
      "Epoch 8/10\n",
      "17963/17963 [==============================] - 88s 5ms/sample - loss: 0.4230 - acc: 0.8475\n",
      "Epoch 9/10\n",
      "17963/17963 [==============================] - 96s 5ms/sample - loss: 0.8037 - acc: 0.7326\n",
      "Epoch 10/10\n",
      "17963/17963 [==============================] - 104s 6ms/sample - loss: 0.6881 - acc: 0.7589\n",
      "4491/4491 [==============================] - 5s 1ms/sample - loss: 1.5711 - acc: 0.6175\n",
      "17963/17963 [==============================] - 20s 1ms/sample - loss: 0.6646 - acc: 0.7710\n",
      "Train on 17964 samples\n",
      "Epoch 1/10\n",
      "17964/17964 [==============================] - 105s 6ms/sample - loss: 1.1647 - acc: 0.5912\n",
      "Epoch 2/10\n",
      "17964/17964 [==============================] - 101s 6ms/sample - loss: 0.9097 - acc: 0.6813\n",
      "Epoch 3/10\n",
      "17964/17964 [==============================] - 104s 6ms/sample - loss: 0.6268 - acc: 0.7675\n",
      "Epoch 4/10\n",
      "17964/17964 [==============================] - 111s 6ms/sample - loss: 0.5250 - acc: 0.8028\n",
      "Epoch 5/10\n",
      "17964/17964 [==============================] - 111s 6ms/sample - loss: 0.3950 - acc: 0.8466\n",
      "Epoch 6/10\n",
      "17964/17964 [==============================] - 111s 6ms/sample - loss: 0.4151 - acc: 0.8416\n",
      "Epoch 7/10\n",
      "17964/17964 [==============================] - 113s 6ms/sample - loss: 0.3441 - acc: 0.8791\n",
      "Epoch 8/10\n",
      "17964/17964 [==============================] - 112s 6ms/sample - loss: 0.2963 - acc: 0.8933\n",
      "Epoch 9/10\n",
      "17964/17964 [==============================] - 118s 7ms/sample - loss: 0.6205 - acc: 0.7823\n",
      "Epoch 10/10\n",
      "17964/17964 [==============================] - 105s 6ms/sample - loss: 0.5718 - acc: 0.7915\n",
      "4490/4490 [==============================] - 6s 1ms/sample - loss: 1.6832 - acc: 0.6196\n",
      "17964/17964 [==============================] - 22s 1ms/sample - loss: 1.9551 - acc: 0.6466\n",
      "Train on 17963 samples\n",
      "Epoch 1/10\n",
      "17963/17963 [==============================] - 111s 6ms/sample - loss: 1.0831 - acc: 0.6312\n",
      "Epoch 2/10\n",
      "17963/17963 [==============================] - 104s 6ms/sample - loss: 0.7327 - acc: 0.7461\n",
      "Epoch 3/10\n",
      "17963/17963 [==============================] - 98s 5ms/sample - loss: 0.6171 - acc: 0.7828\n",
      "Epoch 4/10\n",
      "17963/17963 [==============================] - 96s 5ms/sample - loss: 0.5941 - acc: 0.7962\n",
      "Epoch 5/10\n",
      "17963/17963 [==============================] - 117s 7ms/sample - loss: 0.5202 - acc: 0.8136\n",
      "Epoch 6/10\n",
      "17963/17963 [==============================] - 112s 6ms/sample - loss: 0.4726 - acc: 0.8238\n",
      "Epoch 7/10\n",
      "17963/17963 [==============================] - 100s 6ms/sample - loss: 0.4342 - acc: 0.8388\n",
      "Epoch 8/10\n",
      "17963/17963 [==============================] - 115s 6ms/sample - loss: 0.3975 - acc: 0.8511\n",
      "Epoch 9/10\n",
      "17963/17963 [==============================] - 107s 6ms/sample - loss: 0.4171 - acc: 0.8434\n",
      "Epoch 10/10\n",
      "17963/17963 [==============================] - 107s 6ms/sample - loss: 0.5118 - acc: 0.7955\n",
      "4491/4491 [==============================] - 5s 1ms/sample - loss: 0.4030 - acc: 0.8354\n",
      "17963/17963 [==============================] - 19s 1ms/sample - loss: 0.4892 - acc: 0.8142\n",
      "Train on 17963 samples\n",
      "Epoch 1/10\n",
      "17963/17963 [==============================] - 117s 7ms/sample - loss: 0.9482 - acc: 0.6738\n",
      "Epoch 2/10\n",
      "17963/17963 [==============================] - 102s 6ms/sample - loss: 0.6110 - acc: 0.7813\n",
      "Epoch 3/10\n",
      "17963/17963 [==============================] - 105s 6ms/sample - loss: 0.4917 - acc: 0.8217\n",
      "Epoch 4/10\n",
      "17963/17963 [==============================] - 103s 6ms/sample - loss: 0.4505 - acc: 0.8361\n",
      "Epoch 5/10\n",
      "17963/17963 [==============================] - 107s 6ms/sample - loss: 0.3827 - acc: 0.8527\n",
      "Epoch 6/10\n",
      "17963/17963 [==============================] - 138s 8ms/sample - loss: 0.3812 - acc: 0.8553\n",
      "Epoch 7/10\n",
      "17963/17963 [==============================] - 171s 9ms/sample - loss: 0.3100 - acc: 0.8793\n",
      "Epoch 8/10\n",
      "17963/17963 [==============================] - 191s 11ms/sample - loss: 0.4688 - acc: 0.8326\n",
      "Epoch 9/10\n",
      "17963/17963 [==============================] - 189s 10ms/sample - loss: 0.2819 - acc: 0.8879\n",
      "Epoch 10/10\n",
      "17963/17963 [==============================] - 185s 10ms/sample - loss: 0.4392 - acc: 0.8481\n",
      "4491/4491 [==============================] - 10s 2ms/sample - loss: 0.6481 - acc: 0.7862\n",
      "17963/17963 [==============================] - 32s 2ms/sample - loss: 0.3397 - acc: 0.8733\n",
      "Train on 17963 samples\n",
      "Epoch 1/10\n",
      "17963/17963 [==============================] - 198s 11ms/sample - loss: 1.0760 - acc: 0.6370\n",
      "Epoch 2/10\n",
      "17963/17963 [==============================] - 200s 11ms/sample - loss: 0.8829 - acc: 0.7015\n",
      "Epoch 3/10\n",
      "17963/17963 [==============================] - 173s 10ms/sample - loss: 0.7345 - acc: 0.7458\n",
      "Epoch 4/10\n",
      "17963/17963 [==============================] - 177s 10ms/sample - loss: 0.6581 - acc: 0.7638\n",
      "Epoch 5/10\n",
      "17963/17963 [==============================] - 182s 10ms/sample - loss: 0.5473 - acc: 0.8092\n",
      "Epoch 6/10\n",
      "17963/17963 [==============================] - 187s 10ms/sample - loss: 0.5278 - acc: 0.8109\n",
      "Epoch 7/10\n",
      "17963/17963 [==============================] - 181s 10ms/sample - loss: 0.4369 - acc: 0.8425\n",
      "Epoch 8/10\n",
      "17963/17963 [==============================] - 175s 10ms/sample - loss: 0.4523 - acc: 0.8355\n",
      "Epoch 9/10\n",
      "17963/17963 [==============================] - 210s 12ms/sample - loss: 0.3620 - acc: 0.8584\n",
      "Epoch 10/10\n",
      "17963/17963 [==============================] - 203s 11ms/sample - loss: 0.7679 - acc: 0.7338\n",
      "4491/4491 [==============================] - 16s 4ms/sample - loss: 0.9013 - acc: 0.6676\n",
      "17963/17963 [==============================] - 31s 2ms/sample - loss: 0.7237 - acc: 0.7392\n",
      "Train on 17963 samples\n",
      "Epoch 1/10\n",
      "17963/17963 [==============================] - 200s 11ms/sample - loss: 0.9261 - acc: 0.6970\n",
      "Epoch 2/10\n",
      "17963/17963 [==============================] - 185s 10ms/sample - loss: 0.6453 - acc: 0.7790\n",
      "Epoch 3/10\n",
      "17963/17963 [==============================] - 124s 7ms/sample - loss: 0.5946 - acc: 0.7916\n",
      "Epoch 4/10\n",
      "17963/17963 [==============================] - 112s 6ms/sample - loss: 0.5622 - acc: 0.8048\n",
      "Epoch 5/10\n",
      "17963/17963 [==============================] - 122s 7ms/sample - loss: 0.4300 - acc: 0.8392\n",
      "Epoch 6/10\n",
      "17963/17963 [==============================] - 107s 6ms/sample - loss: 0.3970 - acc: 0.8447\n",
      "Epoch 7/10\n",
      "17963/17963 [==============================] - 109s 6ms/sample - loss: 0.3492 - acc: 0.8668\n",
      "Epoch 8/10\n",
      "17963/17963 [==============================] - 126s 7ms/sample - loss: 0.3238 - acc: 0.8721\n",
      "Epoch 9/10\n",
      "17963/17963 [==============================] - 106s 6ms/sample - loss: 0.3148 - acc: 0.8811\n",
      "Epoch 10/10\n",
      "17963/17963 [==============================] - 116s 6ms/sample - loss: 0.3669 - acc: 0.8574\n",
      "4491/4491 [==============================] - 5s 1ms/sample - loss: 1.2869 - acc: 0.6782\n",
      "17963/17963 [==============================] - 21s 1ms/sample - loss: 0.3127 - acc: 0.8908\n",
      "Train on 17964 samples\n",
      "Epoch 1/10\n",
      "17964/17964 [==============================] - 116s 6ms/sample - loss: 1.0797 - acc: 0.6245\n",
      "Epoch 2/10\n",
      "17964/17964 [==============================] - 106s 6ms/sample - loss: 0.7651 - acc: 0.7293\n",
      "Epoch 3/10\n",
      "17964/17964 [==============================] - 111s 6ms/sample - loss: 0.6183 - acc: 0.7734\n",
      "Epoch 4/10\n",
      "17964/17964 [==============================] - 118s 7ms/sample - loss: 0.5190 - acc: 0.8068\n",
      "Epoch 5/10\n",
      "17964/17964 [==============================] - 103s 6ms/sample - loss: 0.4035 - acc: 0.8479\n",
      "Epoch 6/10\n",
      "17964/17964 [==============================] - 119s 7ms/sample - loss: 0.3700 - acc: 0.8567\n",
      "Epoch 7/10\n",
      "17964/17964 [==============================] - 106s 6ms/sample - loss: 0.3619 - acc: 0.8651\n",
      "Epoch 8/10\n",
      "17964/17964 [==============================] - 110s 6ms/sample - loss: 0.4219 - acc: 0.8350\n",
      "Epoch 9/10\n",
      "17964/17964 [==============================] - 111s 6ms/sample - loss: 0.3317 - acc: 0.8699\n",
      "Epoch 10/10\n",
      "17964/17964 [==============================] - 111s 6ms/sample - loss: 0.2701 - acc: 0.8948\n",
      "4490/4490 [==============================] - 6s 1ms/sample - loss: 0.6174 - acc: 0.8107\n",
      "17964/17964 [==============================] - 20s 1ms/sample - loss: 0.2066 - acc: 0.9193\n",
      "Train on 17963 samples\n",
      "Epoch 1/10\n",
      "17963/17963 [==============================] - 127s 7ms/sample - loss: 1.0947 - acc: 0.6283\n",
      "Epoch 2/10\n",
      "17963/17963 [==============================] - 119s 7ms/sample - loss: 0.8160 - acc: 0.7162\n",
      "Epoch 3/10\n",
      "17963/17963 [==============================] - 107s 6ms/sample - loss: 0.6232 - acc: 0.7837\n",
      "Epoch 4/10\n",
      "17963/17963 [==============================] - 112s 6ms/sample - loss: 0.5871 - acc: 0.7905\n",
      "Epoch 5/10\n",
      "17963/17963 [==============================] - 113s 6ms/sample - loss: 0.4606 - acc: 0.8251\n",
      "Epoch 6/10\n",
      "17963/17963 [==============================] - 105s 6ms/sample - loss: 0.5399 - acc: 0.8002\n",
      "Epoch 7/10\n",
      "17963/17963 [==============================] - 111s 6ms/sample - loss: 0.5764 - acc: 0.7987\n",
      "Epoch 8/10\n",
      "17963/17963 [==============================] - 106s 6ms/sample - loss: 0.4660 - acc: 0.8308\n",
      "Epoch 9/10\n",
      "17963/17963 [==============================] - 120s 7ms/sample - loss: 0.3899 - acc: 0.8484\n",
      "Epoch 10/10\n",
      "17963/17963 [==============================] - 119s 7ms/sample - loss: 0.3484 - acc: 0.8736\n",
      "4491/4491 [==============================] - 6s 1ms/sample - loss: 0.4811 - acc: 0.8475\n",
      "17963/17963 [==============================] - 20s 1ms/sample - loss: 0.2816 - acc: 0.8922\n",
      "Train on 17963 samples\n",
      "Epoch 1/10\n",
      "17963/17963 [==============================] - 112s 6ms/sample - loss: 1.1100 - acc: 0.6090\n",
      "Epoch 2/10\n",
      "17963/17963 [==============================] - 106s 6ms/sample - loss: 0.8938 - acc: 0.6870\n",
      "Epoch 3/10\n",
      "17963/17963 [==============================] - 108s 6ms/sample - loss: 0.6718 - acc: 0.7623\n",
      "Epoch 4/10\n",
      "17963/17963 [==============================] - 101s 6ms/sample - loss: 0.5845 - acc: 0.7848\n",
      "Epoch 5/10\n",
      "17963/17963 [==============================] - 117s 7ms/sample - loss: 0.4670 - acc: 0.8276\n",
      "Epoch 6/10\n",
      "17963/17963 [==============================] - 113s 6ms/sample - loss: 0.3752 - acc: 0.8541\n",
      "Epoch 7/10\n",
      "17963/17963 [==============================] - 113s 6ms/sample - loss: 0.4125 - acc: 0.8450\n",
      "Epoch 8/10\n",
      "17963/17963 [==============================] - 122s 7ms/sample - loss: 0.4078 - acc: 0.8505\n",
      "Epoch 9/10\n",
      "17963/17963 [==============================] - 190s 11ms/sample - loss: 0.3096 - acc: 0.8808\n",
      "Epoch 10/10\n",
      "17963/17963 [==============================] - 166s 9ms/sample - loss: 0.2786 - acc: 0.8983\n",
      "4491/4491 [==============================] - 6s 1ms/sample - loss: 0.5947 - acc: 0.8419\n",
      "17963/17963 [==============================] - 18s 991us/sample - loss: 0.2126 - acc: 0.9179\n",
      "Train on 17963 samples\n",
      "Epoch 1/10\n",
      "17963/17963 [==============================] - 106s 6ms/sample - loss: 1.0666 - acc: 0.6437\n",
      "Epoch 2/10\n",
      "17963/17963 [==============================] - 120s 7ms/sample - loss: 0.8698 - acc: 0.7169\n",
      "Epoch 3/10\n",
      "17963/17963 [==============================] - 123s 7ms/sample - loss: 0.7816 - acc: 0.7326\n",
      "Epoch 4/10\n",
      "17963/17963 [==============================] - 105s 6ms/sample - loss: 0.6829 - acc: 0.7598\n",
      "Epoch 5/10\n",
      "17963/17963 [==============================] - 119s 7ms/sample - loss: 0.5942 - acc: 0.7804\n",
      "Epoch 6/10\n",
      "17963/17963 [==============================] - 114s 6ms/sample - loss: 0.5702 - acc: 0.7906\n",
      "Epoch 7/10\n",
      "17963/17963 [==============================] - 104s 6ms/sample - loss: 0.4608 - acc: 0.8225\n",
      "Epoch 8/10\n",
      "17963/17963 [==============================] - 124s 7ms/sample - loss: 0.5115 - acc: 0.8072\n",
      "Epoch 9/10\n",
      "17963/17963 [==============================] - 114s 6ms/sample - loss: 0.3891 - acc: 0.8474\n",
      "Epoch 10/10\n",
      "17963/17963 [==============================] - 115s 6ms/sample - loss: 0.3325 - acc: 0.8629\n",
      "4491/4491 [==============================] - 6s 1ms/sample - loss: 0.7040 - acc: 0.7604\n",
      "17963/17963 [==============================] - 20s 1ms/sample - loss: 0.2670 - acc: 0.8887\n",
      "Train on 17963 samples\n",
      "Epoch 1/10\n",
      "17963/17963 [==============================] - 126s 7ms/sample - loss: 1.0548 - acc: 0.6404\n",
      "Epoch 2/10\n",
      "17963/17963 [==============================] - 121s 7ms/sample - loss: 0.8256 - acc: 0.7311\n",
      "Epoch 3/10\n",
      "17963/17963 [==============================] - 166s 9ms/sample - loss: 0.7620 - acc: 0.7507\n",
      "Epoch 4/10\n",
      "17963/17963 [==============================] - 204s 11ms/sample - loss: 0.6930 - acc: 0.7652\n",
      "Epoch 5/10\n",
      "17963/17963 [==============================] - 196s 11ms/sample - loss: 0.6367 - acc: 0.7766\n",
      "Epoch 6/10\n",
      "17963/17963 [==============================] - 191s 11ms/sample - loss: 0.5321 - acc: 0.8078\n",
      "Epoch 7/10\n",
      "17963/17963 [==============================] - 140s 8ms/sample - loss: 0.4874 - acc: 0.8198\n",
      "Epoch 8/10\n",
      "17963/17963 [==============================] - 156s 9ms/sample - loss: 0.5618 - acc: 0.7889\n",
      "Epoch 9/10\n",
      "17963/17963 [==============================] - 106s 6ms/sample - loss: 0.4790 - acc: 0.8310\n",
      "Epoch 10/10\n",
      "17963/17963 [==============================] - 138s 8ms/sample - loss: 0.3474 - acc: 0.8657\n",
      "4491/4491 [==============================] - 10s 2ms/sample - loss: 1.0217 - acc: 0.7366\n",
      "17963/17963 [==============================] - 34s 2ms/sample - loss: 0.2717 - acc: 0.8982\n",
      "Train on 17964 samples\n",
      "Epoch 1/10\n",
      "17964/17964 [==============================] - 97s 5ms/sample - loss: 1.0331 - acc: 0.6486\n",
      "Epoch 2/10\n",
      "17964/17964 [==============================] - 106s 6ms/sample - loss: 0.6983 - acc: 0.7472\n",
      "Epoch 3/10\n",
      "17964/17964 [==============================] - 102s 6ms/sample - loss: 0.6091 - acc: 0.7768\n",
      "Epoch 4/10\n",
      "17964/17964 [==============================] - 104s 6ms/sample - loss: 0.7285 - acc: 0.7376\n",
      "Epoch 5/10\n",
      "17964/17964 [==============================] - 99s 6ms/sample - loss: 0.6277 - acc: 0.7699\n",
      "Epoch 6/10\n",
      "17964/17964 [==============================] - 95s 5ms/sample - loss: 0.6251 - acc: 0.7742\n",
      "Epoch 7/10\n",
      "17964/17964 [==============================] - 100s 6ms/sample - loss: 0.5349 - acc: 0.8035\n",
      "Epoch 8/10\n",
      "17964/17964 [==============================] - 100s 6ms/sample - loss: 0.4043 - acc: 0.8474\n",
      "Epoch 9/10\n",
      "17964/17964 [==============================] - 101s 6ms/sample - loss: 0.3250 - acc: 0.8747\n",
      "Epoch 10/10\n",
      "17964/17964 [==============================] - 103s 6ms/sample - loss: 0.2869 - acc: 0.8937\n",
      "4490/4490 [==============================] - 6s 1ms/sample - loss: 0.8083 - acc: 0.7737\n",
      "17964/17964 [==============================] - 19s 1ms/sample - loss: 0.1915 - acc: 0.9298\n",
      "Train on 17963 samples\n",
      "Epoch 1/10\n",
      "17963/17963 [==============================] - 100s 6ms/sample - loss: 1.0101 - acc: 0.6633\n",
      "Epoch 2/10\n",
      "17963/17963 [==============================] - 102s 6ms/sample - loss: 0.6439 - acc: 0.7739\n",
      "Epoch 3/10\n",
      "17963/17963 [==============================] - 99s 6ms/sample - loss: 0.5326 - acc: 0.8121\n",
      "Epoch 4/10\n",
      "17963/17963 [==============================] - 101s 6ms/sample - loss: 0.4563 - acc: 0.8391\n",
      "Epoch 5/10\n",
      "17963/17963 [==============================] - 102s 6ms/sample - loss: 0.6372 - acc: 0.7923\n",
      "Epoch 6/10\n",
      "17963/17963 [==============================] - 110s 6ms/sample - loss: 0.9478 - acc: 0.6875\n",
      "Epoch 7/10\n",
      "17963/17963 [==============================] - 108s 6ms/sample - loss: 0.8779 - acc: 0.7008\n",
      "Epoch 8/10\n",
      "17963/17963 [==============================] - 103s 6ms/sample - loss: 0.8067 - acc: 0.7195\n",
      "Epoch 9/10\n",
      "17963/17963 [==============================] - 97s 5ms/sample - loss: 0.7698 - acc: 0.7352\n",
      "Epoch 10/10\n",
      "17963/17963 [==============================] - 108s 6ms/sample - loss: 0.5937 - acc: 0.7854\n",
      "4491/4491 [==============================] - 6s 1ms/sample - loss: 0.6655 - acc: 0.7593\n",
      "17963/17963 [==============================] - 20s 1ms/sample - loss: 0.4015 - acc: 0.8486\n",
      "Train on 17963 samples\n",
      "Epoch 1/10\n",
      "17963/17963 [==============================] - 104s 6ms/sample - loss: 0.9784 - acc: 0.6640\n",
      "Epoch 2/10\n",
      "17963/17963 [==============================] - 99s 6ms/sample - loss: 0.6692 - acc: 0.7591\n",
      "Epoch 3/10\n",
      "17963/17963 [==============================] - 104s 6ms/sample - loss: 0.5572 - acc: 0.7987\n",
      "Epoch 4/10\n",
      "17963/17963 [==============================] - 103s 6ms/sample - loss: 0.4801 - acc: 0.8206\n",
      "Epoch 5/10\n",
      "17963/17963 [==============================] - 97s 5ms/sample - loss: 0.4011 - acc: 0.8526\n",
      "Epoch 6/10\n",
      "17963/17963 [==============================] - 103s 6ms/sample - loss: 0.3858 - acc: 0.8554\n",
      "Epoch 7/10\n",
      "17963/17963 [==============================] - 101s 6ms/sample - loss: 0.3977 - acc: 0.8479\n",
      "Epoch 8/10\n",
      "17963/17963 [==============================] - 103s 6ms/sample - loss: 0.5316 - acc: 0.8048\n",
      "Epoch 9/10\n",
      "17963/17963 [==============================] - 94s 5ms/sample - loss: 0.4304 - acc: 0.8469\n",
      "Epoch 10/10\n",
      "17963/17963 [==============================] - 88s 5ms/sample - loss: 0.3548 - acc: 0.8659\n",
      "4491/4491 [==============================] - 6s 1ms/sample - loss: 0.7776 - acc: 0.7985\n",
      "17963/17963 [==============================] - 19s 1ms/sample - loss: 0.2764 - acc: 0.8962\n",
      "Train on 17963 samples\n",
      "Epoch 1/10\n",
      "17963/17963 [==============================] - 88s 5ms/sample - loss: 1.0364 - acc: 0.6524\n",
      "Epoch 2/10\n",
      "17963/17963 [==============================] - 86s 5ms/sample - loss: 0.8631 - acc: 0.7059\n",
      "Epoch 3/10\n",
      "17963/17963 [==============================] - 86s 5ms/sample - loss: 0.9829 - acc: 0.6607\n",
      "Epoch 4/10\n",
      "17963/17963 [==============================] - 86s 5ms/sample - loss: 0.8413 - acc: 0.7142\n",
      "Epoch 5/10\n",
      "17963/17963 [==============================] - 86s 5ms/sample - loss: 0.6916 - acc: 0.7542\n",
      "Epoch 6/10\n",
      "17963/17963 [==============================] - 86s 5ms/sample - loss: 0.6493 - acc: 0.7679\n",
      "Epoch 7/10\n",
      "17963/17963 [==============================] - 87s 5ms/sample - loss: 0.6164 - acc: 0.7709\n",
      "Epoch 8/10\n",
      "17963/17963 [==============================] - 86s 5ms/sample - loss: 0.8067 - acc: 0.7116\n",
      "Epoch 9/10\n",
      "17963/17963 [==============================] - 86s 5ms/sample - loss: 0.9470 - acc: 0.6739\n",
      "Epoch 10/10\n",
      "17963/17963 [==============================] - 86s 5ms/sample - loss: 1.0310 - acc: 0.6553\n",
      "4491/4491 [==============================] - 6s 1ms/sample - loss: 1.1047 - acc: 0.6377\n",
      "17963/17963 [==============================] - 19s 1ms/sample - loss: 0.9083 - acc: 0.6854\n",
      "Train on 17963 samples\n",
      "Epoch 1/10\n",
      "17963/17963 [==============================] - 88s 5ms/sample - loss: 1.0059 - acc: 0.6610\n",
      "Epoch 2/10\n",
      "17963/17963 [==============================] - 86s 5ms/sample - loss: 0.8702 - acc: 0.7129\n",
      "Epoch 3/10\n",
      "17963/17963 [==============================] - 86s 5ms/sample - loss: 0.7607 - acc: 0.7491\n",
      "Epoch 4/10\n",
      "17963/17963 [==============================] - 86s 5ms/sample - loss: 0.6177 - acc: 0.7840\n",
      "Epoch 5/10\n",
      "17963/17963 [==============================] - 86s 5ms/sample - loss: 0.4687 - acc: 0.8306\n",
      "Epoch 6/10\n",
      "17963/17963 [==============================] - 86s 5ms/sample - loss: 0.4392 - acc: 0.8400\n",
      "Epoch 7/10\n",
      "17963/17963 [==============================] - 86s 5ms/sample - loss: 0.4818 - acc: 0.8241\n",
      "Epoch 8/10\n",
      "17963/17963 [==============================] - 86s 5ms/sample - loss: 0.8967 - acc: 0.7024\n",
      "Epoch 9/10\n",
      "17963/17963 [==============================] - 86s 5ms/sample - loss: 0.7047 - acc: 0.7606\n",
      "Epoch 10/10\n",
      "17963/17963 [==============================] - 87s 5ms/sample - loss: 0.6886 - acc: 0.7598\n",
      "4491/4491 [==============================] - 6s 1ms/sample - loss: 1.5111 - acc: 0.6081 2s - loss: 1 - ETA: 0s - loss: 1.5093 - acc:\n",
      "17963/17963 [==============================] - 20s 1ms/sample - loss: 0.6838 - acc: 0.7778\n",
      "Train on 17964 samples\n",
      "Epoch 1/10\n",
      "17964/17964 [==============================] - 90s 5ms/sample - loss: 0.9956 - acc: 0.6598\n",
      "Epoch 2/10\n",
      "17964/17964 [==============================] - 87s 5ms/sample - loss: 0.7133 - acc: 0.7493\n",
      "Epoch 3/10\n",
      "17964/17964 [==============================] - 86s 5ms/sample - loss: 0.6653 - acc: 0.7604\n",
      "Epoch 4/10\n",
      "17964/17964 [==============================] - 86s 5ms/sample - loss: 0.7236 - acc: 0.7294\n",
      "Epoch 5/10\n",
      "17964/17964 [==============================] - 86s 5ms/sample - loss: 0.7358 - acc: 0.7331\n",
      "Epoch 6/10\n",
      "17964/17964 [==============================] - 86s 5ms/sample - loss: 0.6322 - acc: 0.7665\n",
      "Epoch 7/10\n",
      "17964/17964 [==============================] - 86s 5ms/sample - loss: 0.5440 - acc: 0.7922\n",
      "Epoch 8/10\n",
      "17964/17964 [==============================] - 86s 5ms/sample - loss: 0.4772 - acc: 0.8116\n",
      "Epoch 9/10\n",
      "17964/17964 [==============================] - 86s 5ms/sample - loss: 0.4379 - acc: 0.8295\n",
      "Epoch 10/10\n",
      "17964/17964 [==============================] - 86s 5ms/sample - loss: 0.5394 - acc: 0.8033\n",
      "4490/4490 [==============================] - 6s 1ms/sample - loss: 0.6392 - acc: 0.7728\n",
      "17964/17964 [==============================] - 19s 1ms/sample - loss: 0.3585 - acc: 0.8588\n",
      "Train on 17963 samples\n",
      "Epoch 1/10\n",
      "17963/17963 [==============================] - 88s 5ms/sample - loss: 1.0366 - acc: 0.6515\n",
      "Epoch 2/10\n",
      "17963/17963 [==============================] - 86s 5ms/sample - loss: 0.7846 - acc: 0.7319\n",
      "Epoch 3/10\n",
      "17963/17963 [==============================] - 86s 5ms/sample - loss: 0.6535 - acc: 0.7748\n",
      "Epoch 4/10\n",
      "17963/17963 [==============================] - 87s 5ms/sample - loss: 0.4732 - acc: 0.8265\n",
      "Epoch 5/10\n",
      "17963/17963 [==============================] - 85s 5ms/sample - loss: 0.4244 - acc: 0.8433\n",
      "Epoch 6/10\n",
      "17963/17963 [==============================] - 84s 5ms/sample - loss: 0.3388 - acc: 0.8734\n",
      "Epoch 7/10\n",
      "17963/17963 [==============================] - 84s 5ms/sample - loss: 0.3167 - acc: 0.8811\n",
      "Epoch 8/10\n",
      "17963/17963 [==============================] - 84s 5ms/sample - loss: 0.3324 - acc: 0.8808\n",
      "Epoch 9/10\n",
      "17963/17963 [==============================] - 84s 5ms/sample - loss: 0.3218 - acc: 0.8790\n",
      "Epoch 10/10\n",
      "17963/17963 [==============================] - 85s 5ms/sample - loss: 0.9527 - acc: 0.6672\n",
      "4491/4491 [==============================] - 5s 1ms/sample - loss: 1.1881 - acc: 0.4772\n",
      "17963/17963 [==============================] - 17s 939us/sample - loss: 1.1925 - acc: 0.5555\n",
      "Train on 17963 samples\n",
      "Epoch 1/10\n",
      "17963/17963 [==============================] - 86s 5ms/sample - loss: 0.9885 - acc: 0.6606\n",
      "Epoch 2/10\n",
      "17963/17963 [==============================] - 84s 5ms/sample - loss: 0.6625 - acc: 0.7636\n",
      "Epoch 3/10\n",
      "17963/17963 [==============================] - 84s 5ms/sample - loss: 0.4974 - acc: 0.8194\n",
      "Epoch 4/10\n",
      "17963/17963 [==============================] - 84s 5ms/sample - loss: 0.7900 - acc: 0.7203\n",
      "Epoch 5/10\n",
      "17963/17963 [==============================] - 84s 5ms/sample - loss: 0.8632 - acc: 0.6869\n",
      "Epoch 6/10\n",
      "17963/17963 [==============================] - 84s 5ms/sample - loss: 0.7400 - acc: 0.7328\n",
      "Epoch 7/10\n",
      "17963/17963 [==============================] - 84s 5ms/sample - loss: 0.6030 - acc: 0.7842\n",
      "Epoch 8/10\n",
      "17963/17963 [==============================] - 85s 5ms/sample - loss: 0.5212 - acc: 0.8064\n",
      "Epoch 9/10\n",
      "17963/17963 [==============================] - 86s 5ms/sample - loss: 0.4620 - acc: 0.8194\n",
      "Epoch 10/10\n",
      "17963/17963 [==============================] - 84s 5ms/sample - loss: 0.4659 - acc: 0.8208\n",
      "4491/4491 [==============================] - 5s 1ms/sample - loss: 0.7095 - acc: 0.7301\n",
      "17963/17963 [==============================] - 16s 913us/sample - loss: 0.3700 - acc: 0.8519\n",
      "Train on 17963 samples\n",
      "Epoch 1/10\n",
      "17963/17963 [==============================] - 86s 5ms/sample - loss: 1.0781 - acc: 0.6386\n",
      "Epoch 2/10\n",
      "17963/17963 [==============================] - 85s 5ms/sample - loss: 0.7793 - acc: 0.7252\n",
      "Epoch 3/10\n",
      "17963/17963 [==============================] - 85s 5ms/sample - loss: 0.6167 - acc: 0.7805\n",
      "Epoch 4/10\n",
      "17963/17963 [==============================] - 84s 5ms/sample - loss: 0.5714 - acc: 0.7883\n",
      "Epoch 5/10\n",
      "17963/17963 [==============================] - 84s 5ms/sample - loss: 0.7084 - acc: 0.7464\n",
      "Epoch 6/10\n",
      "17963/17963 [==============================] - 84s 5ms/sample - loss: 0.4743 - acc: 0.8157\n",
      "Epoch 7/10\n",
      "17963/17963 [==============================] - 84s 5ms/sample - loss: 0.3758 - acc: 0.8499\n",
      "Epoch 8/10\n",
      "17963/17963 [==============================] - 84s 5ms/sample - loss: 0.3445 - acc: 0.8703\n",
      "Epoch 9/10\n",
      "17963/17963 [==============================] - 85s 5ms/sample - loss: 0.3333 - acc: 0.8795\n",
      "Epoch 10/10\n",
      "17963/17963 [==============================] - 85s 5ms/sample - loss: 0.3029 - acc: 0.8924\n",
      "4491/4491 [==============================] - 5s 1ms/sample - loss: 0.7740 - acc: 0.7836\n",
      "17963/17963 [==============================] - 16s 910us/sample - loss: 0.4060 - acc: 0.8668\n",
      "Train on 17963 samples\n",
      "Epoch 1/10\n",
      "17963/17963 [==============================] - 87s 5ms/sample - loss: 0.9470 - acc: 0.6883\n",
      "Epoch 2/10\n",
      "17963/17963 [==============================] - 85s 5ms/sample - loss: 0.6057 - acc: 0.7847\n",
      "Epoch 3/10\n",
      "17963/17963 [==============================] - 85s 5ms/sample - loss: 0.4800 - acc: 0.8338\n",
      "Epoch 4/10\n",
      "17963/17963 [==============================] - 85s 5ms/sample - loss: 0.4130 - acc: 0.8477\n",
      "Epoch 5/10\n",
      "17963/17963 [==============================] - 85s 5ms/sample - loss: 0.4377 - acc: 0.8354\n",
      "Epoch 6/10\n",
      "17963/17963 [==============================] - 85s 5ms/sample - loss: 0.3135 - acc: 0.8760\n",
      "Epoch 7/10\n",
      "17963/17963 [==============================] - 85s 5ms/sample - loss: 0.3361 - acc: 0.8740\n",
      "Epoch 8/10\n",
      "17963/17963 [==============================] - 85s 5ms/sample - loss: 0.2641 - acc: 0.8995\n",
      "Epoch 9/10\n",
      "17963/17963 [==============================] - 85s 5ms/sample - loss: 0.3078 - acc: 0.8870\n",
      "Epoch 10/10\n",
      "17963/17963 [==============================] - 85s 5ms/sample - loss: 0.2719 - acc: 0.8967\n",
      "4491/4491 [==============================] - 6s 1ms/sample - loss: 0.9664 - acc: 0.7537 1\n",
      "17963/17963 [==============================] - 16s 917us/sample - loss: 0.2373 - acc: 0.9084\n",
      "Train on 17964 samples\n",
      "Epoch 1/10\n",
      "17964/17964 [==============================] - 87s 5ms/sample - loss: 1.0726 - acc: 0.6270\n",
      "Epoch 2/10\n",
      "17964/17964 [==============================] - 84s 5ms/sample - loss: 0.8151 - acc: 0.7174\n",
      "Epoch 3/10\n",
      "17964/17964 [==============================] - 84s 5ms/sample - loss: 0.6352 - acc: 0.7635\n",
      "Epoch 4/10\n",
      "17964/17964 [==============================] - 84s 5ms/sample - loss: 0.5315 - acc: 0.8014\n",
      "Epoch 5/10\n",
      "17964/17964 [==============================] - 84s 5ms/sample - loss: 0.5806 - acc: 0.7875\n",
      "Epoch 6/10\n",
      "17964/17964 [==============================] - 85s 5ms/sample - loss: 0.4902 - acc: 0.8186\n",
      "Epoch 7/10\n",
      "17964/17964 [==============================] - 84s 5ms/sample - loss: 0.4855 - acc: 0.8144\n",
      "Epoch 8/10\n",
      "17964/17964 [==============================] - 84s 5ms/sample - loss: 0.4329 - acc: 0.8294\n",
      "Epoch 9/10\n",
      "17964/17964 [==============================] - 84s 5ms/sample - loss: 0.4194 - acc: 0.8334\n",
      "Epoch 10/10\n",
      "17964/17964 [==============================] - 84s 5ms/sample - loss: 0.3475 - acc: 0.8616\n",
      "4490/4490 [==============================] - 6s 1ms/sample - loss: 0.5830 - acc: 0.8176\n",
      "17964/17964 [==============================] - 16s 913us/sample - loss: 0.2957 - acc: 0.8766\n",
      "Train on 17963 samples\n",
      "Epoch 1/10\n",
      "17963/17963 [==============================] - 86s 5ms/sample - loss: 1.1453 - acc: 0.6047\n",
      "Epoch 2/10\n",
      "17963/17963 [==============================] - 85s 5ms/sample - loss: 0.7892 - acc: 0.7271\n",
      "Epoch 3/10\n",
      "17963/17963 [==============================] - 85s 5ms/sample - loss: 0.7764 - acc: 0.7289\n",
      "Epoch 4/10\n",
      "17963/17963 [==============================] - 85s 5ms/sample - loss: 0.5635 - acc: 0.7922\n",
      "Epoch 5/10\n",
      "17963/17963 [==============================] - 85s 5ms/sample - loss: 0.4540 - acc: 0.8345\n",
      "Epoch 6/10\n",
      "17963/17963 [==============================] - 85s 5ms/sample - loss: 0.6466 - acc: 0.7728\n",
      "Epoch 7/10\n",
      "17963/17963 [==============================] - 85s 5ms/sample - loss: 0.5375 - acc: 0.8032\n",
      "Epoch 8/10\n",
      "17963/17963 [==============================] - 85s 5ms/sample - loss: 0.5382 - acc: 0.8058\n",
      "Epoch 9/10\n",
      "17963/17963 [==============================] - 85s 5ms/sample - loss: 0.4464 - acc: 0.8299\n",
      "Epoch 10/10\n",
      "17963/17963 [==============================] - 86s 5ms/sample - loss: 0.3234 - acc: 0.8720\n",
      "4491/4491 [==============================] - 6s 1ms/sample - loss: 0.6161 - acc: 0.7753\n",
      "17963/17963 [==============================] - 17s 954us/sample - loss: 0.3604 - acc: 0.8484\n",
      "Train on 17963 samples\n",
      "Epoch 1/10\n",
      "17963/17963 [==============================] - 88s 5ms/sample - loss: 0.9516 - acc: 0.6749\n",
      "Epoch 2/10\n",
      "17963/17963 [==============================] - 84s 5ms/sample - loss: 0.6721 - acc: 0.7640\n",
      "Epoch 3/10\n",
      "17963/17963 [==============================] - 86s 5ms/sample - loss: 0.6266 - acc: 0.7804\n",
      "Epoch 4/10\n",
      "17963/17963 [==============================] - 85s 5ms/sample - loss: 0.4723 - acc: 0.8259\n",
      "Epoch 5/10\n",
      "17963/17963 [==============================] - 85s 5ms/sample - loss: 0.3894 - acc: 0.8469\n",
      "Epoch 6/10\n",
      "17963/17963 [==============================] - 85s 5ms/sample - loss: 0.3508 - acc: 0.8607\n",
      "Epoch 7/10\n",
      "17963/17963 [==============================] - 85s 5ms/sample - loss: 0.3621 - acc: 0.8574\n",
      "Epoch 8/10\n",
      "17963/17963 [==============================] - 85s 5ms/sample - loss: 0.3120 - acc: 0.8784\n",
      "Epoch 9/10\n",
      "17963/17963 [==============================] - 85s 5ms/sample - loss: 0.5649 - acc: 0.8001\n",
      "Epoch 10/10\n",
      "17963/17963 [==============================] - 85s 5ms/sample - loss: 0.7323 - acc: 0.7384\n",
      "4491/4491 [==============================] - 6s 1ms/sample - loss: 0.9588 - acc: 0.7088\n",
      "17963/17963 [==============================] - 17s 921us/sample - loss: 0.6913 - acc: 0.7645\n",
      "Train on 17963 samples\n",
      "Epoch 1/10\n",
      "17963/17963 [==============================] - 87s 5ms/sample - loss: 1.0434 - acc: 0.6490\n",
      "Epoch 2/10\n",
      "17963/17963 [==============================] - 84s 5ms/sample - loss: 0.8008 - acc: 0.7238\n",
      "Epoch 3/10\n",
      "17963/17963 [==============================] - 85s 5ms/sample - loss: 0.6855 - acc: 0.7562\n",
      "Epoch 4/10\n",
      "17963/17963 [==============================] - 86s 5ms/sample - loss: 0.5453 - acc: 0.7979\n",
      "Epoch 5/10\n",
      "17963/17963 [==============================] - 86s 5ms/sample - loss: 0.4528 - acc: 0.8247\n",
      "Epoch 6/10\n",
      "17963/17963 [==============================] - 89s 5ms/sample - loss: 0.4470 - acc: 0.8296\n",
      "Epoch 7/10\n",
      "17963/17963 [==============================] - 88s 5ms/sample - loss: 0.4567 - acc: 0.8300\n",
      "Epoch 8/10\n",
      "17963/17963 [==============================] - 86s 5ms/sample - loss: 0.3841 - acc: 0.8565\n",
      "Epoch 9/10\n",
      "17963/17963 [==============================] - 86s 5ms/sample - loss: 0.3376 - acc: 0.8741\n",
      "Epoch 10/10\n",
      "17963/17963 [==============================] - 86s 5ms/sample - loss: 0.3623 - acc: 0.8672\n",
      "4491/4491 [==============================] - 6s 1ms/sample - loss: 0.7383 - acc: 0.7978\n",
      "17963/17963 [==============================] - 17s 926us/sample - loss: 0.2789 - acc: 0.9042\n",
      "Train on 17963 samples\n",
      "Epoch 1/10\n",
      "17963/17963 [==============================] - 88s 5ms/sample - loss: 0.9987 - acc: 0.6698\n",
      "Epoch 2/10\n",
      "17963/17963 [==============================] - 85s 5ms/sample - loss: 0.7358 - acc: 0.7535\n",
      "Epoch 3/10\n",
      "17963/17963 [==============================] - 86s 5ms/sample - loss: 0.6070 - acc: 0.7891\n",
      "Epoch 4/10\n",
      "17963/17963 [==============================] - 88s 5ms/sample - loss: 0.4955 - acc: 0.8200\n",
      "Epoch 5/10\n",
      "17963/17963 [==============================] - 86s 5ms/sample - loss: 0.4462 - acc: 0.8393\n",
      "Epoch 6/10\n",
      "17963/17963 [==============================] - 86s 5ms/sample - loss: 0.4243 - acc: 0.8436\n",
      "Epoch 7/10\n",
      "17963/17963 [==============================] - 90s 5ms/sample - loss: 0.4528 - acc: 0.8290\n",
      "Epoch 8/10\n",
      "17963/17963 [==============================] - 90s 5ms/sample - loss: 0.3305 - acc: 0.8744\n",
      "Epoch 9/10\n",
      "17963/17963 [==============================] - 100s 6ms/sample - loss: 0.2693 - acc: 0.8971\n",
      "Epoch 10/10\n",
      "17963/17963 [==============================] - 114s 6ms/sample - loss: 0.5365 - acc: 0.8063\n",
      "4491/4491 [==============================] - 7s 1ms/sample - loss: 1.0219 - acc: 0.6644\n",
      "17963/17963 [==============================] - 19s 1ms/sample - loss: 0.4627 - acc: 0.8420\n",
      "Train on 17964 samples\n",
      "Epoch 1/10\n",
      "17964/17964 [==============================] - 97s 5ms/sample - loss: 1.0510 - acc: 0.6355\n",
      "Epoch 2/10\n",
      "17964/17964 [==============================] - 99s 6ms/sample - loss: 0.8437 - acc: 0.7048\n",
      "Epoch 3/10\n",
      "17964/17964 [==============================] - 106s 6ms/sample - loss: 0.6456 - acc: 0.7685\n",
      "Epoch 4/10\n",
      "17964/17964 [==============================] - 97s 5ms/sample - loss: 0.4892 - acc: 0.8219\n",
      "Epoch 5/10\n",
      "17964/17964 [==============================] - 112s 6ms/sample - loss: 0.4641 - acc: 0.8366\n",
      "Epoch 6/10\n",
      "17964/17964 [==============================] - 106s 6ms/sample - loss: 0.3765 - acc: 0.8628\n",
      "Epoch 7/10\n",
      "17964/17964 [==============================] - 106s 6ms/sample - loss: 0.3643 - acc: 0.8786\n",
      "Epoch 8/10\n",
      "17964/17964 [==============================] - 91s 5ms/sample - loss: 0.3694 - acc: 0.8734\n",
      "Epoch 9/10\n",
      "17964/17964 [==============================] - 90s 5ms/sample - loss: 0.3950 - acc: 0.8589\n",
      "Epoch 10/10\n",
      "17964/17964 [==============================] - 89s 5ms/sample - loss: 0.3174 - acc: 0.8936\n",
      "4490/4490 [==============================] - 6s 1ms/sample - loss: 0.6805 - acc: 0.8220\n",
      "17964/17964 [==============================] - 17s 973us/sample - loss: 0.4182 - acc: 0.8304\n",
      "Train on 17963 samples\n",
      "Epoch 1/10\n",
      "17963/17963 [==============================] - 89s 5ms/sample - loss: 1.0780 - acc: 0.6403\n",
      "Epoch 2/10\n",
      "17963/17963 [==============================] - 88s 5ms/sample - loss: 0.7811 - acc: 0.7269\n",
      "Epoch 3/10\n",
      "17963/17963 [==============================] - 89s 5ms/sample - loss: 0.6436 - acc: 0.7755\n",
      "Epoch 4/10\n",
      "17963/17963 [==============================] - 92s 5ms/sample - loss: 0.5718 - acc: 0.7930\n",
      "Epoch 5/10\n",
      "17963/17963 [==============================] - 86s 5ms/sample - loss: 0.5516 - acc: 0.8011\n",
      "Epoch 6/10\n",
      "17963/17963 [==============================] - 88s 5ms/sample - loss: 0.5103 - acc: 0.8152\n",
      "Epoch 7/10\n",
      "17963/17963 [==============================] - 84s 5ms/sample - loss: 0.4242 - acc: 0.8404\n",
      "Epoch 8/10\n",
      "17963/17963 [==============================] - 84s 5ms/sample - loss: 0.4710 - acc: 0.8264\n",
      "Epoch 9/10\n",
      "17963/17963 [==============================] - 85s 5ms/sample - loss: 0.3652 - acc: 0.8605\n",
      "Epoch 10/10\n",
      "17963/17963 [==============================] - 86s 5ms/sample - loss: 0.3079 - acc: 0.8791\n",
      "4491/4491 [==============================] - 6s 1ms/sample - loss: 0.8090 - acc: 0.7945\n",
      "17963/17963 [==============================] - 16s 889us/sample - loss: 0.3494 - acc: 0.8732\n",
      "Train on 17963 samples\n",
      "Epoch 1/10\n",
      "17963/17963 [==============================] - 85s 5ms/sample - loss: 1.1629 - acc: 0.6017\n",
      "Epoch 2/10\n",
      "17963/17963 [==============================] - 84s 5ms/sample - loss: 0.9253 - acc: 0.6883\n",
      "Epoch 3/10\n",
      "17963/17963 [==============================] - 84s 5ms/sample - loss: 0.8576 - acc: 0.7093\n",
      "Epoch 4/10\n",
      "17963/17963 [==============================] - 86s 5ms/sample - loss: 0.7435 - acc: 0.7380\n",
      "Epoch 5/10\n",
      "17963/17963 [==============================] - 96s 5ms/sample - loss: 0.6279 - acc: 0.7810\n",
      "Epoch 6/10\n",
      "17963/17963 [==============================] - 92s 5ms/sample - loss: 0.4818 - acc: 0.8258\n",
      "Epoch 7/10\n",
      "17963/17963 [==============================] - 87s 5ms/sample - loss: 0.3969 - acc: 0.8601\n",
      "Epoch 8/10\n",
      "17963/17963 [==============================] - 86s 5ms/sample - loss: 0.4197 - acc: 0.8495\n",
      "Epoch 9/10\n",
      "17963/17963 [==============================] - 85s 5ms/sample - loss: 0.4829 - acc: 0.8314\n",
      "Epoch 10/10\n",
      "17963/17963 [==============================] - 85s 5ms/sample - loss: 0.3814 - acc: 0.8598\n",
      "4491/4491 [==============================] - 6s 1ms/sample - loss: 0.6154 - acc: 0.8003\n",
      "17963/17963 [==============================] - 17s 929us/sample - loss: 0.2821 - acc: 0.8829\n",
      "Train on 17963 samples\n",
      "Epoch 1/10\n",
      "17963/17963 [==============================] - 91s 5ms/sample - loss: 1.1616 - acc: 0.5983\n",
      "Epoch 2/10\n",
      " 6784/17963 [==========>...................] - ETA: 1:15 - loss: 0.9004 - acc: 0.6922"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n",
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "grid_result = grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# serialize model to JSON\n",
    "model_json = model.to_json()\n",
    "with open(\"model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"model.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import model_from_json\n",
    "\n",
    "# load json and create model\n",
    "json_file = open('model.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "# load weights into new model\n",
    "loaded_model.load_weights(\"model.h5\")\n",
    "print(\"Loaded model from disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def plot_cm_new(y_true, y_pred, class_names):\n",
    "  cm = confusion_matrix(y_true, y_pred)\n",
    "  fig, ax = plt.subplots(figsize=(18, 16)) \n",
    "  ax = sns.heatmap(\n",
    "      cm, \n",
    "      annot=True, \n",
    "      fmt=\"d\", \n",
    "      cmap=sns.color_palette(\"muted\"),\n",
    "      ax=ax\n",
    "  )\n",
    "\n",
    "  plt.ylabel('Actual')\n",
    "  plt.xlabel('Predicted')\n",
    "  ax.set_xticklabels(class_names)\n",
    "  ax.set_yticklabels(class_names)\n",
    "  b, t = plt.ylim() # discover the values for bottom and top\n",
    "  b += 0.5 # Add 0.5 to the bottom\n",
    "  t -= 0.5 # Subtract 0.5 from the top\n",
    "  plt.ylim(b, t) # update the ylim(bottom, top) values\n",
    "  #plt.show() # ta-da!\n",
    "  plt.savefig(\"confusion_matrix.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc.categories_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_cm(\n",
    "  enc.inverse_transform(y_test),\n",
    "  enc.inverse_transform(y_pred),\n",
    "  enc.categories_[0]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pickle import dump\n",
    "\n",
    "dump(X_test, open('x_test.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dump(y_test, open('y_test.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "print(confusion_matrix(enc.inverse_transform(y_test), enc.inverse_transform(y_pred)))\n",
    "# Accuracy\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(enc.inverse_transform(y_test), enc.inverse_transform(y_pred)))\n",
    "# Recall\n",
    "from sklearn.metrics import recall_score\n",
    "print(recall_score(enc.inverse_transform(y_test), enc.inverse_transform(y_pred), average=None))\n",
    "# Precision\n",
    "from sklearn.metrics import precision_score\n",
    "print(precision_score(enc.inverse_transform(y_test), enc.inverse_transform(y_pred), average=None))\n",
    "# F1 score\n",
    "from sklearn.metrics import f1_score\n",
    "f1_score(enc.inverse_transform(y_test), enc.inverse_transform(y_pred), average=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "binarizer = MultiLabelBinarizer()\n",
    "\n",
    "# This should be your original approach\n",
    "#binarizer.fit(your actual true output consisting of all labels)\n",
    "\n",
    "# In this case, I am considering only the given labels.\n",
    "binarizer.fit(enc.inverse_transform(y_test))\n",
    "\n",
    "f1_score(binarizer.transform(enc.inverse_transform(y_test)), \n",
    "         binarizer.transform(enc.inverse_transform(y_pred)), \n",
    "         average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc.inverse_transform(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_score(binarizer.transform(enc.inverse_transform(y_test)), \n",
    "         binarizer.transform(enc.inverse_transform(y_pred)), \n",
    "         average=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
